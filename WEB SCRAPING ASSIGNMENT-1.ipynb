{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Aassignment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to scrape all headers\n",
    "def sc_header(url = None):\n",
    "    page = requests.get(url)\n",
    "    print(page)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    first_header = soup.find_all([f'h{i}' for i in range(1,10) ])\n",
    "    headers = []\n",
    "    for i in first_header:\n",
    "        headers.append(i.text.replace('\\n',\"\"))\n",
    "        \n",
    "    df = pd.DataFrame({})\n",
    "    df['headers'] = headers[:]\n",
    "    return(df.to_csv('Project_1.csv'))\n",
    "# Calling the function\n",
    "sc_header(url = \"http://en.wikipedia.org/wiki/Main_Page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Main Page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>From today's featured article</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Did you know ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>On this day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>From today's featured list</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Today's featured picture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Other areas of Wikipedia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Wikipedia's sister projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Wikipedia languages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Navigation menu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Personal tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Namespaces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Variants</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Views</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>More</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Search</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Navigation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Contribute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Tools</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Print/export</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>In other projects</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Languages</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          headers\n",
       "0                       Main Page\n",
       "1   From today's featured article\n",
       "2                Did you know ...\n",
       "3                     In the news\n",
       "4                     On this day\n",
       "5      From today's featured list\n",
       "6        Today's featured picture\n",
       "7        Other areas of Wikipedia\n",
       "8     Wikipedia's sister projects\n",
       "9             Wikipedia languages\n",
       "10                Navigation menu\n",
       "11                 Personal tools\n",
       "12                     Namespaces\n",
       "13                       Variants\n",
       "14                          Views\n",
       "15                           More\n",
       "16                         Search\n",
       "17                     Navigation\n",
       "18                     Contribute\n",
       "19                          Tools\n",
       "20                   Print/export\n",
       "21              In other projects\n",
       "22                      Languages"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "header = pd.read_csv('Project_1.csv')\n",
    "header.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to scrape top rated Movie names, IMDB ratings & Year of release\n",
    "def movie_scrape(url = None):\n",
    "    page = requests.get(url)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    r = soup.find_all('td', class_='ratingColumn imdbRating')\n",
    "    m_name = [x.a.text for x in soup.find_all('td', class_ = \"titleColumn\")]\n",
    "    y = [x.text for x in soup.find_all('span', class_='secondaryInfo')]\n",
    "    name = []\n",
    "    rating = []\n",
    "    year = []\n",
    "    for i in m_name:\n",
    "        name.append(i.replace('\\n',\"\"))\n",
    "    for j in y:\n",
    "        year.append(j)\n",
    "    for k in r:\n",
    "        rating.append(k.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['Movie_Name'] = name[:100]\n",
    "    df['Year of Release']= year[:100]\n",
    "    df['Year of Release'] = df['Year of Release'].str.extract('(\\d+)')\n",
    "    df['Rating'] = rating[:100]\n",
    "    return(df.to_csv('Project_2.csv'))\n",
    "    \n",
    "# Calling the function\n",
    "movie_scrape(url = \"https://www.imdb.com/chart/top/?ref_=nv_mv_250\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>1994</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>1974</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>2008</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>1957</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Citizen Kane</td>\n",
       "      <td>1941</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Dangal</td>\n",
       "      <td>2016</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>1952</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Ladri di biciclette</td>\n",
       "      <td>1948</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Kid</td>\n",
       "      <td>1921</td>\n",
       "      <td>8.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Movie_Name  Year of Release  Rating\n",
       "0   The Shawshank Redemption             1994     9.2\n",
       "1              The Godfather             1972     9.1\n",
       "2     The Godfather: Part II             1974     9.0\n",
       "3            The Dark Knight             2008     9.0\n",
       "4               12 Angry Men             1957     8.9\n",
       "..                       ...              ...     ...\n",
       "95              Citizen Kane             1941     8.3\n",
       "96                    Dangal             2016     8.3\n",
       "97       Singin' in the Rain             1952     8.2\n",
       "98       Ladri di biciclette             1948     8.2\n",
       "99                   The Kid             1921     8.2\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_movies = pd.read_csv('Project_2.csv')\n",
    "top_movies.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year of release) and save it in form of a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Function to scrape top rated Indian Movie names, IMDB ratings & Year of release\n",
    "def movie_scrape(url = None):\n",
    "    page = requests.get(url)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    r = soup.find_all('td', class_='ratingColumn imdbRating')\n",
    "    m_name = [x.a.text for x in soup.find_all('td', class_ = \"titleColumn\")]\n",
    "    y = soup.find_all('span', class_='secondaryInfo')\n",
    "    name = []\n",
    "    rating = []\n",
    "    year = []\n",
    "    for i in m_name:\n",
    "        name.append(i.replace('\\n',\"\"))\n",
    "    for j in y:\n",
    "        year.append(j.text.replace('\\n',\"\"))\n",
    "    for k in r:\n",
    "        rating.append(k.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['Movie_Name'] = name[:100]\n",
    "    df['Year of Release']= year[:100]\n",
    "    df['Year of Release'] = df['Year of Release'].str.extract('(\\d+)')\n",
    "    df['Rating'] = rating[:100]\n",
    "    return(df.to_csv('Project_3.csv'))\n",
    "# Calling the function\n",
    "movie_scrape(url = \"https://www.imdb.com/india/top-rated-indian-movies/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_Name</th>\n",
       "      <th>Year of Release</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>1955</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gol Maal</td>\n",
       "      <td>1979</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>1987</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Drishyam 2</td>\n",
       "      <td>2021</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Barfi!</td>\n",
       "      <td>2012</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Legend of Bhagat Singh</td>\n",
       "      <td>2002</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Bommarillu</td>\n",
       "      <td>2006</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Maqbool</td>\n",
       "      <td>2003</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bombay</td>\n",
       "      <td>1995</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Movie_Name  Year of Release  Rating\n",
       "0              Pather Panchali             1955     8.5\n",
       "1                     Gol Maal             1979     8.5\n",
       "2                      Nayakan             1987     8.5\n",
       "3                   Anbe Sivam             2003     8.5\n",
       "4                   Drishyam 2             2021     8.5\n",
       "..                         ...              ...     ...\n",
       "95                      Barfi!             2012     8.0\n",
       "96  The Legend of Bhagat Singh             2002     8.0\n",
       "97                  Bommarillu             2006     8.0\n",
       "98                     Maqbool             2003     8.0\n",
       "99                      Bombay             1995     8.0\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hindi_movies = pd.read_csv('Project_3.csv')\n",
    "hindi_movies.drop('Unnamed: 0',axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Write a python program to scrap book name, author name, genre and book review of any 5 books from‘www.bookpage.com’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def book_scrape(url = None):\n",
    "    page = requests.get(url)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    book_names = [x.a.text for x in soup.find_all('h4', class_ = \"italic\")]\n",
    "    author_names = [x.text for x in soup.find_all('p', class_ = \"sans bold\")]\n",
    "    genre = [x.text for x in soup.find_all('p', class_ = \"genre-links hidden-phone\")]\n",
    "    review = [x.text for x in soup.find_all('p', class_ = \"excerpt\")]\n",
    "    df = pd.DataFrame({})\n",
    "    df['book_names'] = book_names[:5]\n",
    "    df['author_names']= author_names[:5]\n",
    "    df['genre'] = genre[:5]\n",
    "    df['review'] = review[:5]\n",
    "    return(df.to_csv('Project_4.csv'))\n",
    "\n",
    "book_scrape(url = \"https://bookpage.com/reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_names</th>\n",
       "      <th>author_names</th>\n",
       "      <th>genre</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Just as I Am</td>\n",
       "      <td>Cicely Tyson, Robin Miles</td>\n",
       "      <td>Audio / Nonfiction / Biography &amp; Memoir</td>\n",
       "      <td>Narrator Robin Miles bringing the same warmth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Red Island House</td>\n",
       "      <td>Andrea Lee</td>\n",
       "      <td>Fiction / Literary Fiction</td>\n",
       "      <td>The stories of Andrea Lee’s Red Island House a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flight of the Diamond Smugglers</td>\n",
       "      <td>Matthew Gavin Frank</td>\n",
       "      <td>Nonfiction / Memoir / Animals</td>\n",
       "      <td>Matthew Gavin Frank's Flight of the Diamond Sm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The One Thing You'd Save</td>\n",
       "      <td>Linda Sue Park, Robert Sae-Heng</td>\n",
       "      <td>Children's / Middle Grade</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Daughters of Kobani</td>\n",
       "      <td>Gayle Tzemach Lemmon</td>\n",
       "      <td>Nonfiction / History / Middle Eastern History</td>\n",
       "      <td>The story of how young Kurdish women brought d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          book_names                     author_names  \\\n",
       "0                       Just as I Am        Cicely Tyson, Robin Miles   \n",
       "1                   Red Island House                       Andrea Lee   \n",
       "2    Flight of the Diamond Smugglers              Matthew Gavin Frank   \n",
       "3           The One Thing You'd Save  Linda Sue Park, Robert Sae-Heng   \n",
       "4            The Daughters of Kobani             Gayle Tzemach Lemmon   \n",
       "\n",
       "                                           genre  \\\n",
       "0        Audio / Nonfiction / Biography & Memoir   \n",
       "1                     Fiction / Literary Fiction   \n",
       "2                  Nonfiction / Memoir / Animals   \n",
       "3                      Children's / Middle Grade   \n",
       "4  Nonfiction / History / Middle Eastern History   \n",
       "\n",
       "                                              review  \n",
       "0  Narrator Robin Miles bringing the same warmth ...  \n",
       "1  The stories of Andrea Lee’s Red Island House a...  \n",
       "2  Matthew Gavin Frank's Flight of the Diamond Sm...  \n",
       "3                                                     \n",
       "4  The story of how young Kurdish women brought d...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books = pd.read_csv('Project_4.csv')\n",
    "books.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "books['book_names']=books['book_names'].str.replace('★',\"\")\n",
    "books['author_names']=books['author_names'].str.replace('\\n',\"\")\n",
    "books['genre']=books['genre'].str.replace('\\n',\"\")\n",
    "books['review']=books['review'].str.replace('\\n',\"\")\n",
    "books"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape: \n",
    "\n",
    "### i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odi_team(url = None):\n",
    "    page = requests.get(url )\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    teams = soup.find_all('td')\n",
    "    team_names = []\n",
    "    for i in teams:\n",
    "        team_names.append(i.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['ranks'] = team_names[0::5]\n",
    "    df['names'] = team_names[1::5]\n",
    "    df['matches'] = team_names[2::5]\n",
    "    df['points'] = team_names[3::5]\n",
    "    df['rating'] = team_names[4::5]\n",
    "    return(df.to_csv('Project_5_1.csv'))\n",
    "\n",
    "\n",
    "odi_team(url = 'https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranks</th>\n",
       "      <th>names</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>EnglandENG</td>\n",
       "      <td>44</td>\n",
       "      <td>5,405</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>IndiaIND</td>\n",
       "      <td>52</td>\n",
       "      <td>6,102</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>New ZealandNZ</td>\n",
       "      <td>33</td>\n",
       "      <td>3,857</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>AustraliaAUS</td>\n",
       "      <td>39</td>\n",
       "      <td>4,344</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>South AfricaSA</td>\n",
       "      <td>31</td>\n",
       "      <td>3,345</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>PakistanPAK</td>\n",
       "      <td>35</td>\n",
       "      <td>3,490</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>BangladeshBAN</td>\n",
       "      <td>38</td>\n",
       "      <td>3,432</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Sri LankaSL</td>\n",
       "      <td>42</td>\n",
       "      <td>3,372</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>West IndiesWI</td>\n",
       "      <td>49</td>\n",
       "      <td>3,802</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>AfghanistanAFG</td>\n",
       "      <td>31</td>\n",
       "      <td>1,844</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranks           names  matches points  rating\n",
       "0      1      EnglandENG       44  5,405     123\n",
       "1      2        IndiaIND       52  6,102     117\n",
       "2      3   New ZealandNZ       33  3,857     117\n",
       "3      4    AustraliaAUS       39  4,344     111\n",
       "4      5  South AfricaSA       31  3,345     108\n",
       "5      6     PakistanPAK       35  3,490     100\n",
       "6      7   BangladeshBAN       38  3,432      90\n",
       "7      8     Sri LankaSL       42  3,372      80\n",
       "8      9   West IndiesWI       49  3,802      78\n",
       "9     10  AfghanistanAFG       31  1,844      59"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_team = pd.read_csv('Project_5_1.csv')\n",
    "odi_team.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "odi_team.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 ODI Batsmen in men along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odi_batsmen(url = None):\n",
    "    page = requests.get(url )\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    teams = soup.find_all('td')\n",
    "    team_names = []\n",
    "    for i in teams:\n",
    "        team_names.append(i.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['ranks'] = team_names[0::5]\n",
    "    df['names'] = team_names[1::5]\n",
    "    df['team'] = team_names[2::5]\n",
    "    df['points'] = team_names[3::5]\n",
    "    df['rating'] = team_names[4::5]\n",
    "    df['rating'] = df['rating'].str.extract('(\\d+)')\n",
    "    return(df.to_csv('Project_5_2.csv'))\n",
    "\n",
    "\n",
    "odi_batsmen(url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranks</th>\n",
       "      <th>names</th>\n",
       "      <th>team</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>870</td>\n",
       "      <td>911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>842</td>\n",
       "      <td>885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>837</td>\n",
       "      <td>846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>818</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "      <td>798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>790</td>\n",
       "      <td>820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "      <td>880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "      <td>808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Kane Williamson</td>\n",
       "      <td>NZ</td>\n",
       "      <td>765</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Quinton de Kock</td>\n",
       "      <td>SA</td>\n",
       "      <td>755</td>\n",
       "      <td>813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ranks                names team  points  \\\n",
       "0                                       1          Virat Kohli  IND     870   \n",
       "1                               2                 Rohit Sharma  IND     842   \n",
       "2                               3                   Babar Azam  PAK     837   \n",
       "3                               4                  Ross Taylor   NZ     818   \n",
       "4                               5                  Aaron Finch  AUS     791   \n",
       "5                               6          Francois du Plessis   SA     790   \n",
       "6                               7                 David Warner  AUS     773   \n",
       "7                                       8            Shai Hope   WI     773   \n",
       "8                               9              Kane Williamson   NZ     765   \n",
       "9                              10              Quinton de Kock   SA     755   \n",
       "\n",
       "   rating  \n",
       "0     911  \n",
       "1     885  \n",
       "2     846  \n",
       "3     841  \n",
       "4     798  \n",
       "5     820  \n",
       "6     880  \n",
       "7     808  \n",
       "8     799  \n",
       "9     813  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_batsmen = pd.read_csv('Project_5_2.csv')\n",
    "odi_batsmen.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "odi_batsmen.ranks.replace(np.NaN,8,inplace = True)\n",
    "odi_batsmen.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 ODI bowlers along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odi_bowlers(url = None):\n",
    "    page = requests.get(url )\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    teams = soup.find_all('td')\n",
    "    team_names = []\n",
    "    for i in teams:\n",
    "        team_names.append(i.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['ranks'] = team_names[0::5]\n",
    "    df['names'] = team_names[1::5]\n",
    "    df['team'] = team_names[2::5]\n",
    "    df['points'] = team_names[3::5]\n",
    "    df['rating'] = team_names[4::5]\n",
    "    df['rating'] = df['rating'].str.extract('(\\d+)')\n",
    "    return(df.to_csv('Project_5_3.csv'))\n",
    "\n",
    "\n",
    "odi_bowlers(url = 'https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranks</th>\n",
       "      <th>names</th>\n",
       "      <th>team</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>722</td>\n",
       "      <td>770.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "      <td>712.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>700</td>\n",
       "      <td>841.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>694</td>\n",
       "      <td>694.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>675</td>\n",
       "      <td>676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>665</td>\n",
       "      <td>724.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "      <td>733.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>658</td>\n",
       "      <td>695.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Mohammad Amir</td>\n",
       "      <td>PAK</td>\n",
       "      <td>647</td>\n",
       "      <td>663.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "      <td>729.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ranks              names team  points  \\\n",
       "0                                       1        Trent Boult   NZ     722   \n",
       "1                               2           Mujeeb Ur Rahman  AFG     708   \n",
       "2                               3             Jasprit Bumrah  IND     700   \n",
       "3                               4               Mehedi Hasan  BAN     694   \n",
       "4                               5               Chris Woakes  ENG     675   \n",
       "5                               6              Kagiso Rabada   SA     665   \n",
       "6                               7             Josh Hazlewood  AUS     660   \n",
       "7                               8          Mustafizur Rahman  BAN     658   \n",
       "8                               9              Mohammad Amir  PAK     647   \n",
       "9                              10                Pat Cummins  AUS     646   \n",
       "\n",
       "   rating  \n",
       "0   770.0  \n",
       "1   712.0  \n",
       "2   841.0  \n",
       "3   694.0  \n",
       "4   676.0  \n",
       "5   724.0  \n",
       "6   733.0  \n",
       "7   695.0  \n",
       "8   663.0  \n",
       "9   729.0  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_bowler = pd.read_csv('Project_5_3.csv')\n",
    "odi_bowler.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "odi_bowler.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "### i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odi_team_women(url = None):\n",
    "    page = requests.get(url )\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    teams = soup.find_all('td')\n",
    "    team_names = []\n",
    "    for i in teams:\n",
    "        team_names.append(i.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['ranks'] = team_names[0::5]\n",
    "    df['names'] = team_names[1::5]\n",
    "    df['matches'] = team_names[2::5]\n",
    "    df['points'] = team_names[3::5]\n",
    "    df['rating'] = team_names[4::5]\n",
    "    return(df.to_csv('Project_6_1.csv'))\n",
    "\n",
    "\n",
    "odi_team_women(url = 'https://www.icc-cricket.com/rankings/womens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranks</th>\n",
       "      <th>names</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>AustraliaAUS</td>\n",
       "      <td>15</td>\n",
       "      <td>2,436</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>South AfricaSA</td>\n",
       "      <td>24</td>\n",
       "      <td>2,828</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>EnglandENG</td>\n",
       "      <td>17</td>\n",
       "      <td>1,993</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>IndiaIND</td>\n",
       "      <td>20</td>\n",
       "      <td>2,226</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>New ZealandNZ</td>\n",
       "      <td>18</td>\n",
       "      <td>1,696</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West IndiesWI</td>\n",
       "      <td>12</td>\n",
       "      <td>1,025</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>PakistanPAK</td>\n",
       "      <td>15</td>\n",
       "      <td>1,101</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>BangladeshBAN</td>\n",
       "      <td>5</td>\n",
       "      <td>306</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sri LankaSL</td>\n",
       "      <td>11</td>\n",
       "      <td>519</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>IrelandIRE</td>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranks           names  matches points  rating\n",
       "0      1    AustraliaAUS       15  2,436     162\n",
       "1      2  South AfricaSA       24  2,828     118\n",
       "2      3      EnglandENG       17  1,993     117\n",
       "3      4        IndiaIND       20  2,226     111\n",
       "4      5   New ZealandNZ       18  1,696      94\n",
       "5      6   West IndiesWI       12  1,025      85\n",
       "6      7     PakistanPAK       15  1,101      73\n",
       "7      8   BangladeshBAN        5    306      61\n",
       "8      9     Sri LankaSL       11    519      47\n",
       "9     10      IrelandIRE        2     25      13"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_team_women = pd.read_csv('Project_6_1.csv')\n",
    "odi_team_women.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "odi_team_women"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii) Top 10 women’s ODI players along with the records of their team and rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odi_player_women(url = None):\n",
    "    page = requests.get(url )\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    teams = soup.find_all('td')\n",
    "    team_names = []\n",
    "    for i in teams:\n",
    "        team_names.append(i.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['ranks'] = team_names[0::5]\n",
    "    df['names'] = team_names[1::5]\n",
    "    df['matches'] = team_names[2::5]\n",
    "    df['points'] = team_names[3::5]\n",
    "    df['rating'] = team_names[4::5]\n",
    "    df['rating'] = df['rating'].str.extract('(\\d+)')\n",
    "    df['ranks'] = df['ranks'].str.extract('(\\d+)')\n",
    "    return(df.to_csv('Project_6_2.csv'))\n",
    "\n",
    "\n",
    "odi_player_women(url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranks</th>\n",
       "      <th>names</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>773</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>749</td>\n",
       "      <td>834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>741</td>\n",
       "      <td>741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>740</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>719</td>\n",
       "      <td>797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>699</td>\n",
       "      <td>725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>693</td>\n",
       "      <td>839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>691</td>\n",
       "      <td>766</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ranks              names matches  points  rating\n",
       "0    1.0        Lizelle Lee      SA     773     773\n",
       "1    2.0     Tammy Beaumont     ENG     765     765\n",
       "2    3.0        Meg Lanning     AUS     749     834\n",
       "3    4.0    Stafanie Taylor      WI     746     765\n",
       "4    5.0       Alyssa Healy     AUS     741     741\n",
       "5    6.0  Amy Satterthwaite      NZ     740     756\n",
       "6    7.0    Smriti Mandhana     IND     719     797\n",
       "7    8.0    Laura Wolvaardt      SA     699     725\n",
       "8    9.0        Mithali Raj     IND     693     839\n",
       "9   10.0       Ellyse Perry     AUS     691     766"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_women_player = pd.read_csv('Project_6_2.csv')\n",
    "odi_women_player.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "odi_women_player.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii) Top 10 women’s ODI all-rounder along with the records of their team and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def odi_allrounder_women(url = None):\n",
    "    page = requests.get(url )\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'html.parser')\n",
    "    teams = soup.find_all('td')\n",
    "    team_names = []\n",
    "    for i in teams:\n",
    "        team_names.append(i.text.replace('\\n',\"\"))\n",
    "    df = pd.DataFrame({})\n",
    "    df['ranks'] = team_names[0::5]\n",
    "    df['names'] = team_names[1::5]\n",
    "    df['matches'] = team_names[2::5]\n",
    "    df['points'] = team_names[3::5]\n",
    "    df['rating'] = team_names[4::5]\n",
    "    df['rating'] = df['rating'].str.extract('(\\d+)')\n",
    "    return(df.to_csv('Project_6_3.csv'))\n",
    "\n",
    "\n",
    "odi_allrounder_women(url = 'https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ranks</th>\n",
       "      <th>names</th>\n",
       "      <th>matches</th>\n",
       "      <th>points</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>460</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "      <td>559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>390</td>\n",
       "      <td>412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>357</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>301</td>\n",
       "      <td>308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>274</td>\n",
       "      <td>305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>252</td>\n",
       "      <td>421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Katherine Brunt</td>\n",
       "      <td>ENG</td>\n",
       "      <td>236</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>223</td>\n",
       "      <td>241</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    ranks             names matches  points  \\\n",
       "0                                       1      Ellyse Perry     AUS     460   \n",
       "1                               2           Stafanie Taylor      WI     410   \n",
       "2                               3            Marizanne Kapp      SA     390   \n",
       "3                               4             Deepti Sharma     IND     357   \n",
       "4                               5            Natalie Sciver     ENG     349   \n",
       "5                               6             Jess Jonassen     AUS     301   \n",
       "6                               7             Sophie Devine      NZ     274   \n",
       "7                               8          Dane van Niekerk      SA     252   \n",
       "8                               9           Katherine Brunt     ENG     236   \n",
       "9                              10          Ashleigh Gardner     AUS     223   \n",
       "\n",
       "   rating  \n",
       "0     548  \n",
       "1     559  \n",
       "2     412  \n",
       "3     397  \n",
       "4     349  \n",
       "5     308  \n",
       "6     305  \n",
       "7     421  \n",
       "8     270  \n",
       "9     241  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "odi_ar_women = pd.read_csv('Project_6_3.csv')\n",
    "odi_ar_women.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "odi_ar_women.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The scraped data should include Product Name, Price, Image URL and Average Rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url= 'https://www.amazon.in/s?bbn=1389401031&rh=n%3A1389401031%2Cp_36%3A1318506031&dc&qid=1616327014&rnid=1318502031&ref=lp_1389401031_nr_p_36_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [503]>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scraping was not accepted by Amazon India. Status code 503 means that the server is down for maintenance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Write a python program to extract information about the local weather from the National Weather Service website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day extended forecast display for the city. The data should include period, short description, temperature and description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def weather_report(url = None):\n",
    "    page = requests.get(url)\n",
    "    data = page.text\n",
    "    soup = BeautifulSoup(data, 'lxml')\n",
    "    Period = [x.text for x in soup.find_all('p', class_=\"period-name\")]\n",
    "    Short_desc = [x.text for x in soup.find_all('p', class_=\"short-desc\")]\n",
    "    Temp_high = [x.text for x in soup.find_all('p', class_=\"temp temp-high\")]\n",
    "    Temp_Low = [x.text for x in soup.find_all('p', class_=\"temp temp-low\")]\n",
    "    Desc = [x.text for x in soup.find_all('div', class_=\"col-sm-10 forecast-text\")]\n",
    "    def twolists(list1, list2):\n",
    "        newlist = []\n",
    "        a1 = len(list1)\n",
    "        a2 = len(list2)\n",
    "        for i in range(max(a1, a2)):\n",
    "            if i < a1:\n",
    "                newlist.append(list1[i])\n",
    "            if i < a2:\n",
    "                newlist.append(list2[i])\n",
    "\n",
    "        return newlist\n",
    "\n",
    "    temp = twolists(Temp_high,Temp_Low)\n",
    "    df = pd.DataFrame({})\n",
    "    df['Period'] = Period\n",
    "    df['Short_desc'] = Short_desc\n",
    "    df['temp'] = temp\n",
    "    df['Long_Desc'] = Desc[0:9]\n",
    "    \n",
    "    return(df.to_csv('Project_8.csv'))\n",
    "\n",
    "\n",
    "weather_report(url= 'https://forecast.weather.gov/MapClick.php?CityName=San+Francisco&state=CA&site=MTR&textField1=37.775&textField2=-122.418#.YFeTkXtR3IU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import numpy as np\\nimport pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Short_desc</th>\n",
       "      <th>temp</th>\n",
       "      <th>Long_Desc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Overnight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Mostly clear, with a low around 46. West wind ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>Low: 46 °F</td>\n",
       "      <td>Mostly sunny, with a high near 65. West wind 5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MondayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>High: 69 °F</td>\n",
       "      <td>Mostly clear, with a low around 47. West north...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Low: 47 °F</td>\n",
       "      <td>Sunny, with a high near 69. North wind 7 to 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TuesdayNight</td>\n",
       "      <td>Clear</td>\n",
       "      <td>High: 70 °F</td>\n",
       "      <td>Clear, with a low around 49. North wind 13 to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Low: 49 °F</td>\n",
       "      <td>Sunny, with a high near 70.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>WednesdayNight</td>\n",
       "      <td>Mostly Clear</td>\n",
       "      <td>High: 65 °F</td>\n",
       "      <td>Mostly clear, with a low around 49.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Low: 49 °F</td>\n",
       "      <td>Sunny, with a high near 65.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ThursdayNight</td>\n",
       "      <td>Clear</td>\n",
       "      <td>Low: 46 °F</td>\n",
       "      <td>Clear, with a low around 46.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Period    Short_desc         temp  \\\n",
       "0       Overnight  Mostly Clear  High: 65 °F   \n",
       "1          Monday  Mostly Sunny   Low: 46 °F   \n",
       "2     MondayNight  Mostly Clear  High: 69 °F   \n",
       "3         Tuesday         Sunny   Low: 47 °F   \n",
       "4    TuesdayNight         Clear  High: 70 °F   \n",
       "5       Wednesday         Sunny   Low: 49 °F   \n",
       "6  WednesdayNight  Mostly Clear  High: 65 °F   \n",
       "7        Thursday         Sunny   Low: 49 °F   \n",
       "8   ThursdayNight         Clear   Low: 46 °F   \n",
       "\n",
       "                                           Long_Desc  \n",
       "0  Mostly clear, with a low around 46. West wind ...  \n",
       "1  Mostly sunny, with a high near 65. West wind 5...  \n",
       "2  Mostly clear, with a low around 47. West north...  \n",
       "3  Sunny, with a high near 69. North wind 7 to 12...  \n",
       "4  Clear, with a low around 49. North wind 13 to ...  \n",
       "5                        Sunny, with a high near 70.  \n",
       "6                Mostly clear, with a low around 49.  \n",
       "7                        Sunny, with a high near 65.  \n",
       "8                       Clear, with a low around 46.  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "whtr = pd.read_csv('Project_8.csv')\n",
    "whtr.drop('Unnamed: 0',axis = 1,inplace = True)\n",
    "whtr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Write a python program to scrape ‘software developer’ job listings from ‘Monster.com’. It should include all the jobs listed for the next 5 pages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url = 'https://www.monstergulf.com/srp/results?query=Software%20Developer,software%20development&searchId=721946ce-6082-455c-9442-ec2c0bccba86')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website dosent allow data scraping but loop can be used to scrape data from 5 subsequent pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Write a python program to scrape ‘data scientist’ job listings for location ‘New Delhi’ from ‘Monster.com’. It should include all the jobs listed for the next 5 pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [403]>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests.get(url='https://www.monsterindia.com/srp/results?query=Data%20Scientist&locations=Delhi&searchId=5e30757d-9dd9-46ee-9e46-8f6035fe76ef')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Website dosent allow data scraping but loop can be used to scrape data from 5 subsequent pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
